% Notwendige Start-Codezeile
\documentclass[a4paper, 12pt, twoside]{article}

% Präambel

% Pakete
\usepackage[left=3cm,right=2.5cm,bottom=3.5cm,top=2.5cm]{geometry} % Ok die Seitenrändereinstellungen passen so.
\usepackage{amsfonts}
\usepackage[utf8]{inputenc} % Kodierung
\usepackage[ngerman]{babel} % Sprache
\usepackage{amssymb}        % Mathematische Symbole wie z.b ganze Zahlen, reelle Zahlen etc.
\usepackage{amsmath}        % Um diverse mathematische Symbole nutzen zu können.
\usepackage{amsthm}         % Um Definitionen, Theoreme, Bemerkungen, Beispiele machen zu können.
\usepackage{mathtools}      % Dieses Paket liefert nützliche Werkzeuge, z.B "defined as equal" - sign uvm.
\usepackage{enumitem}       % Um individuelle Listen zu bauen.
\usepackage{xcolor}         % Um farbigen Text machen zu können. Diesen kann ich nutzen um wichtige persönliche Notizen hervorzuheben.
\usepackage{fancyhdr}       % Um saubere Kopf und Fußzeilen sowie Seitenzahlen zu erzeugen.
\usepackage{setspace}       % Damit kann ich Leerzeilen im Dokument einfügen.
\usepackage{graphicx}       % Einbinden von externen Bildern
\usepackage{hyperref}
% insbesondere beim Inhaltsverzeichnis nötig, da dieses sonst zu
% gequetscht aussieht.


% Symbolverzeichnis
%\usepackage{nomencl}
%\makenomenclature
%\renewcommand{\nomname}{Symbolverzeichnis}


% Globale Festlegungen
\setlength{\topsep}{4ex plus0.5ex minus0.5ex} % Festlegung: Größe der Absätze nach Definition, Theorem, etc.
\setlength\parindent{0pt} % Festlegung: Kein Einschub nach rechts.
\setstretch{1.2} % Festlegung: Zeilenabstand ist 1.2 statt 1.
\raggedbottom % twoside sorgt dafür, dass der Platz, der durch \\ und einer Leerzeile erzeugt wird sehr groß ist und nicht nur eine Leerzeile, was ich nämlich erzielen möchte.
              % Dieses Kommando sorgt dafür, dass dies wiederhergestellt wird und twoside trotzdem wirkt.

% Vorlagen
% 1) [before = \leavevmode\vspace{-\baselineskip}]
% // Um bei Theoremen mit Listen zu starten.

% Eigene Befehle

\newcommand\logeq{\mathrel{\vcentcolon\Longleftrightarrow}} % Dieser Befehl realisiert mittels "\logeq" ein "defnierendes Äquivalenzzeichen".
\newcommand{\ts}{\thinspace} % Damit ich nicht so viel schreiben muss, wenn ich kleine Leerzeilen hinzufügen möchte. Was ich oft tue bei Mengendefinitionen, da mir der Platz dort zu klein ist.

% Eigene Theoremstyles
% Format 1
\newtheoremstyle{Format1}
{\topsep}   % ABOVESPACE
{\topsep}   % BELOWSPACE
{\normalfont}  % BODYFONT
{0pt}       % INDENT (empty value is the same as 0pt)  % Das rückt den Kopf nach rechts ein
{\bfseries} % HEADFONT
{\newline}  % HEADPUNCT
{5pt plus 1pt minus 1pt} % HEADSPACE
{}          % CUSTOM-HEAD-SPEC


% Eigene Theorem-Umgebungen
\theoremstyle{Format1} % Alle Theoremumgebungen hierunter folgen den Spezifikationen vom "Format 1" - Theoremstil
\newtheorem{Def}{Definition}[section]       % Definition
\newtheorem*{Definition}{Definition}        % Definition (unnummeriert)
\newtheorem{Bsp}[Def]{Beispiel}             % Beispiel
\newtheorem{Bem}[Def]{Bemerkung}            % Bemerkung
\newtheorem{Satz}[Def]{Satz}                % Satz
\newtheorem*{Bez}{Bezeichnung}              % Bezeichnung (unnummeriert)
\newtheorem{Folg}[Def]{Folgerung}           % Folgerung
\newtheorem*{Folgerung}{Folgerung}          % Folgerung (unnummeriert)
\newtheorem{Lem}[Def]{Lemma}                % Lemma
\newtheorem*{Grundmodell}{Grundmodell}
\newtheorem*{Aussage}{Aussage}
\newtheorem*{Herleitung}{Herleitung}

% Code aus Stackexchange, welcher bei Nutzen von Norm oder Betrag automatisch passende Betragsgrößen generiert, also die Beträge dem Ausdruck entsprechend vergrößert:

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

% Swap the definition of \abs* and \norm*, so that \abs
% and \norm resizes the size of the brackets, and the
% starred version does not.
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

% Code aus Stackexchange: Sorgt dafür, dass die Abstände zwischen Zeilen in Allign Umgebungen etwas größer sind, also normal. Die Standardabstände sind mir zu gering.

\addtolength{\jot}{0.5em}


% Beginn des Dokumentes
\begin{document}

\newgeometry{} % Damit die Titelseite nicht von den Einstellungen des geometry packages beeinflusst wird.
% Titelblatt der Arbeit
\begin{titlepage}
	\begin{center}
		\vspace*{1cm}

		\Huge
		\textbf{Bachelorarbeit}

		\vspace{0.5cm}
		\LARGE
		Optimale Zuordnungen auf Geometrischen Graphen

		\vspace{1.5cm}
		\large Sebastian Koletzko\\

		\vspace{1cm}
		Datum: 17.12.23

		\vfill

		\vspace{5cm}

		%\includegraphics[width=0.4\textwidth]{RuhrU}

		\large
		Fakultät für Mathematik
		\\
		Ruhr-Universität Bochum
		\\
		\vspace{0.5cm}
		Prof. Dr. Maike Buchin
		\\
		Dr. Daniela Kacso

	\end{center}
\end{titlepage}

\restoregeometry % Damit die Titelseite nicht vom geoemtry-package beeinflusst wird - Endcodezeile.

\newpage\null\thispagestyle{empty}\newpage % Nach der Titelseite kommt immer eine leere Seite, denn die nachfolgende Seite, ist die Rückseite der Titelseite. Und ich möchte nicht auf der Rückseite direkt anfangen.

\thispagestyle{empty} % Damit keine Seitenzahl auf der Erklärung-Seite auftaucht.

\textbf{Eigenständigkeitserklärung:}
\\
Hiermit erkläre ich, dass ich die heute eingereichte Bachelorarbeit selbstständig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt sowie Zitate kenntlich gemacht habe.
Bei der vorliegenden Bachelorarbeit handelt es sich um in Wort und Bild völlig übereinstimmende Exemplare. Ich erkläre weiterhin, dass die vorliegende Arbeit noch nicht im Rahmen eines anderen Prüfungsverfahrens eingereicht wurde.
\\
\\
Witten, den 17.12.23
\\
\\
Sebastian Koletzko


% Inhaltsverzeichnis. (Dieses wird nach Sektionen geordnet)
\newpage
\tableofcontents
\newpage\null\thispagestyle{empty}\newpage % Eine Leerseite nach dem Inhaltsverzeichnis.
\section{Einleitung}

Die geometrische Graphentheorie ist ein Zweig der Graphentheorie, die sich dem Studium von Graphen verschreibt, deren Knoten und Kanten wir mit geometrischen Objekten identifizieren.
Sie ist eng verwandt mit der Topologischen Graphentheorie, welche sich mit der Darstellung von Graphen in topologischen Räumen beschäftigt.

Graphen, denen eine konkrete Darstellung - z.B im euklidischen Raum - zugewiesen wurde, bezeichnen wir als eingebettete Graphen.
Bekannte Vertreter dieser Klasse sind unter Anderen die planaren Graphen. Dies sind Graphen, deren deren Kanten sich als Jordan-Kurven so in die euklidische
Ebene einbetten lassen, dass sich zwei Kanten höchstens an ihren inzidenten Knoten schneiden.
\\
TODO: Beispiel
\\
In dieser Arbeit wollen wir uns insbesondere mit den sogenannten geometrischen Graphen beschäftigen. Hierbei handelt es sich um Graphen,
deren Kanten in Form eines Geradenstücks in der euklidischen Ebene dargestellt werden.
Geometrische Graphen eignen sich insbesondere zur Repräsentation von realen Netzwerken (wie z.B. Straßennetzen).
\\
Wir wollen geometrische Graphen vergleichen.
Inbesondere wollen wir geometrische Graphen bezüglich ihrer jeweiligen Repräsentation/Rekonstruktion eines Netzwerks miteinander vergleichen.
Wir interessieren uns dabei für die Ähnlichkeit zweier geometrischer Graphen. Für uns bedeutet Ähnlichkeit zum einen die geometrische Ähnlichkeit gegeben durch die
Einbettung der Graphen in die Ebene aber auch insbesondere bezüglich ihrer Konnektivität.
Zum Vergleich zweier Graphen bzw. zwei geometrischer Objekte stößt man in der Literatur unweigerlich auf das Konzept eines Abstandsmaßes zwischen Graphen.
Unter einem Abstandsmaß verstehen im Allgemeinen eine reellwertige Zuordung zum Vergleich zweier geometrischer Objekte wie z.B. zum Vergleich von zwei Kurven im euklidischen Raum.
Für den Vergleich von eingebetteten Graphen existieren dabei bereits einige bekannte Abstandsmaße.
\\
Einige Abstandsmaße erfassen z.B. beim Vergleich von eingebetteten Graphen lediglich die Repräsentation der Graphen im Sinne ihrer Punktmenge im euklidischen Raum berücksichtigen dabei nicht die ihnen
durch ihre abstrakte Beschreibung ausgewiesene Konnektivität.
TODO: Um Referenzen ergänzen.
\\
Eine zentrale Fragestellung dabei ist fortlaufend, wie man neue Abstandsmaße auf Graphen definieren kann und unter welchen Bedingungen sie sich auch für potentiell komplexe Graphen effizient berechnen lassen.
\\
Dabei interessieren wir uns insbesondere auch für die mathematischen Eigenschaften eines Abstandsmaßes sowie seiner implizierten 'Notion' der Ähnlichkeit auf die zu vergleichenden Objekte.
\\
Um die Ählichkeit zweier eingebetter Graphen insbesondere in Bezug auf die Konnektivität des Graphen zu beschreiben, haben Akitaya et al. \cite{Akitaya} neue Abstandsmaße eingeführt und ihre Eigenschaften untersucht.
\\
Besonderheit bei diesen Abstandmaßen ist, dass sie auf einer stetigen Zuordnung zwischen den zu vergleichenden Graphen basieren.
\\
Vor dem Hintergrund, dass die "directed (weak) graph distance" eine bottle-neck distance beschreibt, wird bei der min-sum graph distance das Ziel verfolgt, lokale Abstände zu berücksichtigen.
Darauf aufbauend haben \cite{Buchin} Buchin et al. ein weiteres Abstandsmaß definiert, welches mögliche lokale Optimierungen der Graph-Zuordnung berücksichtigt.
[Ein kleiner Text über den Stand der Wissenschaft]

Mit diesem Abstandsmaß wollen wir uns in dieser Arbeit hauptsächlich beschäftigen.
In Kapitel 2 fassen wir dazu zunächst die Notation und die zentralen Begriffe aus [2] zusammen, welche den Grundstein für die Auseinandersetzung mit dem neuen Abstandsmaß bilden.
In Kapitel 3 werden wir den Min-Sum-Graph-Abstand motivieren und einführen. Anschließend werden wir uns mit den Bedingungen und einem Ansatz beschäftigen, um den Min-Sum-Graph-Abstand
unter Verwendung des Fréchet-Abstands in Polynomialzeit zu berechnen.
Abschließend beweisen wir in Kapitel 4 die NP-Schwerheit des Min-Sum-Graph-Abstands unter Verwendung des Fréchet-Abstands für allgemeine Graphen.

Zur Berechnung des Min-Sum-Graph-Abstands haben Buchin et al in [1] einen Algorithmus beschrieben, welcher unter gewissen Einschränkungen in Polynomialzeit läuft.
Bevor wir uns abschließend diesem Algorithmus widmen, werden wir die NP-Schwerheit des Min-Sum-Graph-Abstands für allgemeine Graphen beweisen.
\newpage

\section{Grundlagen}
Wir betrachten hier $ \mathbb{R}^n $ grundsätzlich als metrischen Raum, versehen mit der euklidischen Norm.
\begin{Def}
	Ein \textit{Weg} ist eine stetige Abbildung $ \phi: [0,1] \to \mathbb{R}^n $ von einem geschlossenen Intervall $[0,1]$ nach $\mathbb{R}^n$.
	\\
	Das Bild von $I$ unter $\phi$ nennen wir \textit{Kurve}.
	\\
	Wir bezeichnen $\phi(0)$ als den \textit{Startpunkt} und $\phi(1)$ als den \textit{Endpunkt} des Weges und bezeichnen die Menge
	$\{\phi(0), \phi(1)\}$ auch als \textit{Randpunkte} des Weges. Dabei ist grundsätzlich $\phi(a) \neq \phi(b)$ anzunehmen.
	\\
	Ein \textit{einfacher Weg} ist ein Weg, welcher injektiv auf $[0,1]$ ist.
\end{Def}

\begin{Def}
	Sei $G=(V,E)$ ein endlicher, ungerichteter Graph.

	Unter einem \textit{eingebetteten Graphen} verstehen wir einen Graphen $G$
	zusammen mit seiner \textit{Einbettung} $\omega: G \to \mathbb{R}^n$, welche
	jedem Knoten $v \in V$ einen eindeutigen Punkt $v_0 \in \mathbb{R}^n$ zuordnet und jeder Kante $\{u,v\} \in E$
	einen einfachen Weg $\phi: [0,1]: \to \mathbb{R}^n$ mit den Randpunkten $\omega(u)$ und $\omega(v)$ zuordnet.
	\\
	Ist jede Kante von $G$ in den euklidischen Raum als Geradenstück mit den zur jeweiligen Kante inzidenten Knoten als Randpunkte realisiert, so
	nennen wir $G$ einen \textit{geradlinig eingebetteten Graphen}.
	\\
	Dabei dürfen sich Kanten von $G$ grundsätzlich in einem Punkt schneiden.
	\\
	\\
	Für einen eingebetteten Knoten $v \in V$ definieren wir seinen \textit{$\varepsilon$-Ball} $B_{\varepsilon}(v)$ als die Menge
	$\{x \in \mathbb{R}^n.: \|v-x\| \leq \varepsilon\}$
	und für eine eingebette Kante $e \in E$ definieren wir ihren \textit{$\varepsilon$-Schlauch} $T_{\varepsilon}(e)$ als die Menge
	$\{x \in \mathbb{R}^n: \min_{a \in e}\|a-x\| \leq \varepsilon\}$.
	\\
	\\
	Einen in die euklidische Ebene geradlinig eingebetteten Graphen bezeichnen wir als \textit{geometrischen Graphen}.
\end{Def}

\begin{Def}
	Einfacher Weg in einem Graphen
	\\
	Sei $G$ ein geradlinig eingebetteter Graph.
	\\
	Ein einfacher Weg in $G$ ist eine stetige, injektive Abbildung $\tilde{\phi}: [0,1] \to G$.
	Dabei betrachten bezüglich der Stetigkeit $G$ als Topologischen Graphen (TODO: Referenz).
	\\
	Die Kurve von $\tilde{\phi}$ repräsentiert in gewisser Weise eine zusammenhängende Komponente von $G$ bestehend aus
	Kanten und Teilkanten. Dabei ist es jedoch nicht erlaubt, dass $\tilde{\phi}$ Umwege über Kantenschnitte in $G$ nimmt.
	Wir fordern also insbesondere, dass $\tilde{\phi}$ die abstrakte Konnektivität von $G$ berücksichtigt.
	\\
	Wenn wir im weiteren Verlauf von einem einfachen Weg sprechen, so beziehen wir die damit verbundene Kurve als Bild des Weges
	mit ein und benutzen die beiden Begriffe mitunter synonym. Dies soll hervorheben, dass die eigentliche Parametrisierung
	der Kurve nicht von entscheidender Bedeutung ist. Entscheidend für den weiteren Verlauf ist für uns nur die Vorraussetzung, dass die
	Parametrisierung stetig und injektiv ist.
	\\
	Für einen Weg $W$ in einem einegebetteten Graphen definieren wir seine \textit{Länge} als die Anzahl der Geradenstücke, aus
	denen sich $W$ zusammensetzt. Wir kennzeichnen die Länge von $W$ durch $|W|$.
\end{Def}

\subsection{Abstände auf geometrischen Graphen}

Seien $ G_1=(V_1, E_1) $ und $ G_2=(V_2, E_2) $ für den gesamten weiteren Verlauf geometrische Graphen mit
$n_1 = |V_1|, m_1 = |E_1|, n_2 = |V_2|$ und $m_2 = |E_2|$.

\begin{Def} \label{Definition Graph-Zuordnung}
	Graph-Zuordnung (engl. graph mapping)
	Wir nennen eine Abbildung $s: G_1 \to G_2 $ eine \textit{Graph-Zuordnung}, falls
    	\begin{enumerate}
		\item[1)] s jeden Knoten $ v \in V_1 $ auf einen Punkt innerhalb von $ G_2 $ abbildet und
		\item[2)] s alle Kanten $ \{u,v\} \in E_1 $ auf einen einfachen Weg in $G_2$ abbildet, wobei $s(u), s(v)$ die Randpunkte des Weges sind.
    	\end{enumerate}

	Eine Graph-Zuordnung definiert somit eine stetige Abbildung von $ G_1 $ nach $ G_2 $ und ist im Allgemeinen weder injektiv noch surjektiv.
	In gewisser Weise könnte man hier einen Bezug zum Begriff der \textit{Einbettung} aus der Topologie herstellen. (TODO: Referenz).
	Hier ist es jedoch so, dass wir für die Existenz einer Graph-Zuordnung von $ G_1 $ nach $ G_2 $ nicht so strenge Bedingungen stellen, insbesondere
	müssen $G_1$ und $G_2$ nicht homöomorph sein, damit eine Graph-Abbildung zwischen ihnen existieren kann.
\end{Def}

\begin{Def} \label{Definition Fréchet-Abstand}
	Fréchet-Abstand (engl. fréchet distance)
	Für zwei Wege $ f, g: [0,1] \to \mathbb{R}^n $ definieren wir den \textit{Fréchet-Abstand} von $f$ und $g$ als
	$$ \delta_F(f,g) =  \inf_{\sigma:[0,1] \to [0,1]} \; \max_{t \in [0,1]} \lVert f(t)-(g(\sigma(t)) \rVert, $$
	wobei sich $\sigma $ über alle orientierungserhaltenen Homöomorphismen erstreckt.
	\\
	\\
	Wir definieren den \textit{schwachen Fréchet-Abstand} von $f$ und $g$ als
	$$\delta_{wF}(f,g) =\inf_{\alpha , \beta :[0,1] \to [0,1]} \; \max_{t \in [0,1]} \lVert f(\alpha(t))-(g(\sigma(t)) \rVert,$$
	wobei sich $\alpha$ und $\beta$ über alle stetigen Abbildungen erstrecken, welche die Randpunkte fixieren, also $\alpha(0) = \beta(0) = 0$
	und $\alpha(1) = \beta(1) = 1$.
	\\
	\\
	Die Klammer-Notation, z.B. $ \delta_{(w)F} $, benutzen wir zugunsten der Kompaktheit nachfolgend, wenn wir im jeweiligen Kontext den Fréchet-Abstand sowie den schwachen Fréchet-Abstand zugleich -
	wir schreiben in diesem Fall auch \textit{(schwacher) Fréchet-Abstand} - adressieren wollen.
	\\
	\\
	Zur Anschauung des Fréchet-Abstands stelle man sich $f$ und $g$ als Kurven im $\mathbb{R}^2$ vor. Der (euklidische) Abstand zwischen $f$ und $g$ zum Zeitpunkt $t_0 \in [0,1]$ entspricht gerade der Länge der Strecke
	mit den Randpunkten $f(t_0)$ und $g(t_0)$. Bei dem Fréchet-Abstand dürfen wir eine Kurve reparametrisieren, um den maximal angenommenen euklidischen Abstand zwischen $f$ und $g$ zu minimieren.
	TODO: Anschauung ergänzen
	\\
	Für den Fréchet-Abstand darf einer von beiden auf seinem festgelegten Weg - welcher der Spur der Kurve entspricht - zu jedem Zeitpunkt beliebig beschleunigen oder sogar stehenbleiben, aber nicht die Richtung wechseln.
	Dies mit dem Ziel, die dabei maximal angenommene Länge der Leine möglichst zu minimieren.
	Für den schwachen Fréchet-Abstand dürfen der Mann sowie sein Hund auf ihrem Weg beliebig beschleunigen und auch die Richtung ändern.
	\\
	Wir bezeichnen einen solchen maximal-angenommen Abstand zwischen zwei Objekten sinngemäß auch als \textit{Flaschenhals-Abstand}.
	\\
\end{Def}

\begin{Def} \label{Definition Graph-Abstand}
	Abstände auf Graphen
	Wir definieren den \textit{gerichteten Graph-Abstand} $ \vec{\delta}_G $ als
	$$ \vec{\delta}_G(G_1,G_2) = \inf_{s: G_1 \to G_2} \: \max_{e \in E_1} \delta_F(e, s(e)) $$
	und den \textit{gerichteten schwachen Graph-Abstand} $ \vec{\delta}_{wG} $ als
	$$  \vec{\delta}_{wG}(G_1,G_2) = \inf_{s: G_1 \to G_2} \: \max_{e \in E_1} \vec{\delta}_{wF}(e, s(e)), $$
	wobei s sich über alle Graph-Zuordnungen erstreckt.
\end{Def}

Im Vergleich zu anderen Abstandsmaßen (TODO: Referenz hinzufügen), welche primär die geometrische Ähnlichkeit von $G_1$ und $G_2$ berücksichtigen, hat neben den geometrischen Eigenschaften auch die (abstrakte) Konnektivtät von $G_1$ und $G_2$
Implikationen für das Ausmaß des gerichteten (schwachen) Graph-Abstands.
\\
\\
TODO: Beispiel/Erklärung
\\
Ähnlich wie der (schwache) Fréchet-Abstand beschreibt auch der gerichtete (schwache) Graphabstand einen Flaschenhals-Abstand.
Generell können viele Graph-Zuordnungen $s: G_1 \to G_2$ existieren, die den gerichteten (schwachen) Graph-Abstand einhalten.

\subsection{Lokale Optimierungen}

Im Anwendungsfall kann man sich z.B. mehrere Rekonstruktionen $G_{1,1}, ..., G_{1,n}$ eines Netzwerkes $G_2$ vorstellen.
Anschließend stelle man sich nun die Frage, welche der Rekonstruktionen dem urpsprünglichen Netzwerk $G_2$ am ähnlichsten ist bzw. dieses entsprechend eines konkreten Abstandsmaßes
für Graphen am besten.
Der gerichtete (schwache) Graph-Abstand zwischen einem $G_{1i}$ $(i \in \{1,...,n\})$ und $G_2$ beschreibt dabei lediglich eine obere Schranke für die größte Abweichung zwischen
einer Rekonstruktion $G_{1i}$ und $G_2$.
Unter Umständen haben evlt. sogar alle $G_{1i}$ denselben Flaschenhals-Abstand zu $G_2$, da sie dieselbe entscheidende Abweichung bei der Rekonstruktion von $G_2$ erzeugen.
Insbendere interessieren wir uns hier nun für die lokale Güte der Rekonstruktion, welche für den gerichteten (schwachen) Graph-Abstand keine Rolle spielt.
\\
\\
Dies motiviert die Einführung eines weiteren Abstandsmaßes auf Graphen, welches auch lokale Optimierungen bei der Zuordnungen der Kanten in Betracht zieht.
\\
\\
Zuvor merken wir an, dass im Allgemeinen eine Graph-Zuordnung $\tilde{s}: G_1 \to G_2$, die jede Kante $e \in E_1$ optimal bezüglich des (schwachen)
Fréchet-Abstands auf $G_2$ abbildet, so dass $\delta_{(w)F}(e, \tilde{s}(e)) \leq \delta_{(w)F}(e, s(e))$, nicht existiert (siehe dazu [2], Seite xx).
\\
\\
Als Alternative bietet es sich an, die summierten Abstände zwischen den Kanten in $G_1$ und ihren Bildern in $G_2$ unter der Graph-Zuordnung zu minimieren.

\subsection{Optimale Graph-Zuordnungen} \label{Optimale Graphzuordnungen}
Damit widmen wir uns nun einem Abstandsmaß, welches für uns im weiteren Verlauf das Optimalitätskriterum - bezüglich lokaler Abstände zwischen Kanten und ihren Bildern - für Graph-Zuordnungen beschreibt.

\begin{Def} \label{Definition Min-Sum}
	Min-Sum-Graph-Abstand (engl. min-sum graph distance)

	Für die Graphen $G_1$ und $G_2$ definieren wir allgemein den \textit{Min-Sum-Graph-Abstand}$_{dist}(G_1, G_2)$ als
	$$\min_{s: G_1 \to G_2} \sum_{e \in E_1} dist(e, s(e)),$$
	wobei sich $s$ über alle Graph-Zuordnungen von $G_1$ nach $G_2$ erstreckt und $dist$ ein unspezifisches Abstandsmaß für den Vergleich von Kurven im euklidischen Raum repräsentiert.
	\\
	\\
	Wählen wir für $dist$ den (schwachen) Fréchet-Abstand als zugrundeliegendes Abstandsmaß, so bezeichnen wir entsprechend
	\textit{Min-Sum}$_{(w)F}(G_1, G_2)$ als $$\min_{s: G_1 \to G_2} \sum_{e \in E_1} \delta_{(w)F}(e, s(e)).$$
	\\
	\\
	Ferner bezeichnen wir mit $Sum_{(w)F}(s) = \sum_{e \in E_1}\delta_{(w)F}(e, s(e))$ die Summe (schwachen) Fréchet-Abstände zwischen den Kanten
	in $G_1$ und ihren durch $s$ zugeordneten Wegen in $G_2$.
	\\
	Wir nennen $s$ eine Min-Sum$_{(w)F}$ Zuordnung, falls
	\\
	$Sum_{(w)F}(s) = \text{Min-Sum-Graph-Abstand}_{(w)F}(G_1,G_2)$.

\end{Def}

\section{Ein polynomieller Algorithmus}

Im Nachfolgenden werden wir zur Berechnung des Min-Sum-Graph-Abstands$_{(w)F}$ den Algorithmus aus [1] beschreiben und diesen anhand eines konkreten Beispiels ausführen.
Sei $G_1$ von nun an ein Baum, also ein kreisfreier, zusammenhängender Graph.

\subsection{Einschränkungen an die Graph-Zuordnungen} \label{Einschränkungen}
In der Definition des Min-Sum-Graph-Abstands$_{(w)F}(G_1, G_2)$ ziehen wir alle Graph-Zuordnungen $s: G_1 \to G_2$ in Betracht.
Im weiteren Verlauf werden wir diese Menge mit zwei Einschränkungen versehen.
Die erste Einschränkung ist dabei optional. Die zweite Einschränkung wird notwendig sein, um die polynomielle Laufzeit des Algorithmus zu gewährleisten.

\begin{Def}
	$\varepsilon$-Platzierung (engl. $\varepsilon$-Placement)
	Eine \textit{$\varepsilon$-Platzierung eines Knotens $v \in V_1$} ist eine maximal zusammenhängende Komponente von $G_2$ eingeschränkt auf $B_{\varepsilon}(v)$.
	Eine \textit{$\varepsilon$-Platzierung einer Kante $e = \{u,v\} \in E_1$} ist ein Weg $W$ in $G_2$, welcher eine Platzierung $p_u$ von $u$ mit einer Platzierung $p_v$ von $v$
	so verbindet, dass $\delta_F(e, W) \leq \varepsilon$.
	\\
	In diesem Fall nennen wir $p_u$ und $p_v$ \textit{voneinander erreichbar}.
	\\
	Eine \textit{$\varepsilon$-Platzierung von $G_1$} ist eine Graph-Zuordnung $s: G_1 \to G_2$, so dass $s$ jede Kante $e \in G_1$ auf eine $\varepsilon$-Platzierung von $e$ abbildet.
	\\
	Eine schwache $\varepsilon$-Platzierung einer Kante $e = \{u,v\} \in E_1$ ist ein Weg $W$ in $G_2$, welcher eine Platzierung $p_u$ von $u$ mit einer Platzierung $p_v$ von $v$
	so verbindet, dass $\delta_{wF}(e, W) \leq \varepsilon$.
	\\
	In diesem Fall nennen wir $p_u$ und $p_v$ \textit{schwach voneinander erreichbar}.
	\\
	Eine schwache \textit{$\varepsilon$-Platzierung von $G_1$} ist eine Graph-Zuordnung $s: G_1 \to G_2$, so dass $s$ jede Kante $e \in G_1$ auf eine schwache $\varepsilon$-Platzierung von $e$ abbildet.
	\\
	\\
	Synonym für $\varepsilon$-Platzierung eines Knotens bzw. einer Kante benutzen wir mitunter auch die Begriffe \textit{Knoten-Platzierung} und \textit{Kanten-Platzierung}.
\end{Def}

\subsubsection{Erste Einschränkung} \label{Erste Einschränkung}

Wir haben den Begriff des Min-Sum-Graph-Abstands primär vor dem Hintergrund motiviert, optimale Graph-Zuordnungen auf geometrischen Graphen zu betrachten,
die bereits einen Flaschenhals-Abstand wie den gerichteten (schwachen) Graph-Abstand einhalten.

Um diesen Zusammenhang zu erhalten, werden wir die in Betrachtung zu ziehenden Graph-Zuordnungen zunächst auf die Menge
\begin{center}
	$\{s: G_1 \to G_2 \text{ $|$ } s$ ist eine (schwache) $\varepsilon$-Platzierung von $G_1$ nach $G_2\}$
\end{center}
einschränken.
\\
Generell können wir auch $\varepsilon \geq \vec{\delta}_{(w)F}(G_1, G_2)$ fordern, für größere $\varepsilon$ erhöht sich entsprechend der Freiheitsgrad in der Auswahl
der möglichen Graph-Zuordnungen und damit verrringert sich auch potentiell der unter dieser Einschränkung geltende Min-Sum$_{(w)F}$ Abstand.
\\
Wir merken an dieser Stelle insbesondere an, dass eine $\varepsilon$-Platzierung von $G_1$ nach $G_2$ für $\varepsilon < \vec{\delta}_{(w)F}(G_1,G_2)$
nicht existieren kann. Dies folgt direkt aus den Definitionen \ref{Definition Graph-Abstand} und \ref{Definition Min-Sum}.

\subsubsection{Zweite Einschränkung} \label {Zweite Einschränkung}
Da wir hier zur Berechnung der Abstände zwischen einer Kante $\{u,v\} \in E_1$ und ihrem Bild $s(\{u,v\})$ unter einer Graph-Zuordnung $s$ den (schwachen) Fréchet-Abstand verwenden,
hat die Wahl der Bilder $s(u)$ und $s(v)$, innerhalb der entsprechenden $\varepsilon$-Platzierungen von $u$ und $v$, eine direkte Auswirkung auf die summierten Abstände.
Anders ausgedrückt: Im Gegensatz zum gerichteten (schwachen) Graph-Abstand ist $\sum_{e \in E_1}\delta_{(w)F}(e, s(e))$ nicht invariant unter dem Freiheitsgrad, den $s$
bei der Wahl der Bildpunkte in $G_2$, $s(u)$ und $s(v)$ hat.
\\
TODO: Dies besser beschreiben
\\
\\
TODO: Skizze
\\
\\
TODO: Erläuterung der Skizze
\\
\\
Um dies zu umgehen, werden wir für einen Knoten $u \in E_1$ sein Bild unter einer Graph-Zuordnung für jede seiner $\varepsilon$-Platzierung fixieren.
Als Fixpunkt wählen wir dafür einen Punkt in der $\varepsilon$-Platzierung mit minimalem Abstand zu $u$.

\subsection{Ansätze und Beschreibung eines polynomiellen Algorithmus} \label{Grundidee des Algorithmus}
Um unter den Einschränkungen \ref{Erste Einschränkung} und \ref{Zweite Einschränkung} an die zu betrachtenden Graph-Zuordnungen von $G_1$ nach $G_2$
Min-Sum$_{(w)F}(G_1,G_2)$ zu berechnen, wollen wir eine
eine $\varepsilon$-Platzierung $s: G_1 \to G_2$ konstruieren, die das Optimalitätskriterium (siehe \ref{Optimale Graphzuordnungen}) erfüllt.
Für eine solche Abbildung $s$ gilt dann entsprechend $\sum_{e \in E_1}\delta_{(w)F}(e, s(e)) = \text{Min-Sum}_{(w)F}(G_1,G_2)$.
\\
\\
Der algorithmische Ansatz zur Lösung des Entscheidungsproblems, ob eine $\varepsilon$-Platzierung von $G_1$ existiert (siehe [2] Seiten 9-11), liefert das
Grundgerüst für die Konstruktion von $s$. Wir wollen den algorithmischen Ansatz motivieren und die Berechnungsschritte im Detail beschreiben.
Der Algorithmus gliedert sich in insgesamt 4 Einzelschritte, die wir im Verlauf des Kapitels entsprechend kennzeichnen werden.

\subsubsection{$\varepsilon$-Platzierungen der Knoten} \label{Platzierungen der Knoten}
Die Zuordnung eines Knotens $u \in V_1$ auf einen Punkt innerhalb seiner $\varepsilon$-Platzierung impliziert stets die Randpunkte $w(0)$, $w(1)$
für einen einfachen Weg $w: [0,1] \to G_2$, auf den eine zu $u$ inzidente Kante $\{u,v\} \in E_1$ durch eine Graph-Zuordndung $s$ abgebildet wird.
Dass diese Randpunkte innerhalb der $\varepsilon$-Platzierung ihrer jeweiligen Knoten liegen, ist ein notwendiges Kriterium dafür, dass der (schwache) Fréchet-Abstand
zwischen der Kante und ihrem Bild unter $s$ nicht größer als $\varepsilon$ ist. Aus der Definition des (schwachen) Fréchet-Abstands (siehe \ref{Definition Fréchet-Abstand}) folgt direkt, dass
$\delta_{(w)F}(e, w) \geq max{\{\|u-w(0)\|, \|v-w(1)\|\}}$.
\\
\\
In diesem Sinne berechnen wir zunächst alle $\varepsilon$-Platzierungen der Knoten in $G_1$ und bezeichnen für einen Knoten $v \in V_1$ mit $P(v)$ die Menge aller $\varepsilon$-Platzierungen von $v$.

\subsubsection{Schritt 1} \label{Schritt 1}
Wir initialisieren $\varepsilon$ mit $\varepsilon \geq \vec{\delta}_{(w)F}(G_1, G_2)$. Da $G_1$ ein Baum ist, können wir
$\vec{\delta}_{wF}(G_1, G_2)$ in $O(...)$ und $\vec{\delta}_F(G_1, G_2)$ in $O(...)$ berechnen. Siehe dazu ...
Anschließend berechnen wir die $\varepsilon$-Platzierungen aller Knoten in $G_1$. Jeder Knoten in $G_1$ hat $O(m_2)$
$\varepsilon$-Platzierungen, womit insgesamt $(n_1*m_2)$ $\varepsilon$-Platzierung zu berechnen sind.
Für jeden Knoten lassen sich seine $\varepsilon$-Platzierungen über einen Standard-Algorithmus zur Berechnung von
zusammenhängenden Komponenten in Graphen ermitteln, dessen Laufzeit linear in der Größe von $G_2$ ist (?Referenz?).
Die Laufzeit - und Speicherkomplexität beträgt somit $O(n_1*m_2)$.

\subsubsection{Schritt 2} \label{Schritt 2}
Für jede Kante $\{u, v\} \in E_1$ berechnen wir nun die Erreichbarkeiten zwischen den $\varepsilon$-Platzierungen der Knoten von $\{u,v\}$.
Dabei ist für jede Kombination $p_u, p_v$ von $\varepsilon$-Platzierungen von $u$ und $v$ zu jeweils zu entscheiden, ob sie voneinander (schwach) erreichbar sind.

Um die schwache Erreichbarkeit zu entscheiden, ist die Existenz eines einfachen Weges zwischen zwei Knoten-Platzierungen
$p_u,p_v$, welcher vollständig innerhalb von $T_{\varepsilon}(\{u,v\})$ liegt, bereits ein hinreichendes Kriterium (siehe [3], Seite 83).

Schränken wir $G_2$ auf $T_{\varepsilon}(\{u,v\})$ ein, so sind alle Knoten-Platzierungen innerhalb derselben zusammenhängenden Komponente von $G_2$
schwach voneinander erreichbar. Entsprechend speichern wir für eine zusammenhängende Komponente von $G_2$ innerhalb $T_{\varepsilon}(e)$ jeweils zwei Listen mit den
der Knoten-Platzierungen $P(u)$ und $P(v)$.

Die schwachen Erreichbarkeiten zwischen allen Knoten-Platzierungen entlang einer Kante in $G_1$ lassen sich somit mit einer Laufzeit von $O(m_2)$ berechnen.
Insgesamt beträgt die Zeit - und Speicherkomplexität zur Berechnung der Erreichbarkeiten aller Kanten in $G_1$ $O(m_1*m_2)$.
\\
\\
Für den Fréchet-Abstand ist die Existenz eines einfachen Weges $w$ innerhalb von $T_{\varepsilon}(\{u,v\})$, welcher $p_u$ und $p_v$ miteinander verbindet,
lediglich ein notwendiges Kriterium dafür, dass $p_u$ und $p_v$ voneinander erreichbar sind. Wir müssen für $w$ explizit entscheiden,
ob $\delta_F(\{u,v\}, w) \leq \varepsilon$.
\\
\\
Dabei können wir für zwei Wege $Y$ und $Z$ das Entscheidungsproblem $\delta_F(Y,Z) \leq \varepsilon$ in $O(\|Y\|*\|Z\|)$ lösen (Siehe [3], Seite 77).
Da $\{u,v\}$ ein Geradenstück ist, gilt $\|\{u,v\}\| = 1$. Damit können wir die Erreichbarkeit zwischen $\{u,v\}$ und $w$ in $O(|w|)$ entscheiden.
Da $w$ per Bedingung ein einfacher Weg ist, besteht $w$ aus maximal $m_2$ Kanten (bzw. Teilkanten) von $G_2$.
Zur Speicherung der Erreichbarkeiten speichern wir für jede $\varepsilon$-Platztierung von $u$ eine Liste mit $\varepsilon$-Platzierungen von $v$, die
über ein $w$ voneinander erreichbar sind. Um die Liste für ein $p_u \in P(u)$ zu berechnen, starten wir eine Graph-Suche zur Ermittlung eines
Weges in $G_2$ beginnend bei $p_u$. Verlassen wir während der Suche entweder $T_{\varepsilon}(\{u,v\})$ bzw. überschreitet der Fréchet-Abstand $\varepsilon$,
so entfernen wir den Suchzweig aus der Liste der möglichen Abzweigungen in $G_2$.
Für eine Kante in $G_1$ beträgt die Laufzeit der Suche somit $O(m_2^2)$ und pro Kante haben wir bis zu $m_2^2$ Paare voneinander erreichbarer Knoten-Platzierungen.
Für alle Kanten in $G_1$ liegt die Speicher - und Laufzeitkomplexität damit bei $O(m_1*m_2^2)$.

\subsubsection{Existenz einer $\varepsilon$-Platzierung von $G_1$}
Bis zu diesem Schritt haben wir die (schwachen) Erreichbarkeiten zwischen Knoten-Platzierungen paarweise ermittelt.
Nun wollen wir unseren Wortschatz um den Begriff der Knoten-Platzierungen insofern erweitern, dass wir in unserem konkreten Fall die Existenz einer
$\varepsilon$-Platzierung von $G_1$ garantieren können.
\\
Falls nämlich z.B. der Knoten $u$ neben $\{u,v\}$ nun noch eine weitere inzidente Kante $\{u,w\} \in E_1$ hat, so muss neben einem $p_v \in P(v)$ insbesondere auch
ein $p_w \in P(w)$ existieren, so dass die Paare $\{p_u,p_v\}$ und $\{p_v,p_u\}$ (schwach) voneinander erreichbar sind. Die paarweise (schwache) Erreichbarkeit
zwischen Knoten-Platzierungen von einander adjazenten Knoten ist offensichtlich ein notwendiges Kriterium für die Existenz einer $\varepsilon$ von $G_1$.
Dies motiviert die folgende Definition.

\begin{Def}
	Gültige $\varepsilon$-Platzierung (engl. valid placement)
	Eine $\varepsilon$-Platzierung $p_v$ eines Knotens $v$ nennen wir (schwach) \textit{gültig}, falls für jeden Nachbarn $u$ von $v$
	eine $\varepsilon$-Platzierung $p_u$ existiert, so dass $p_v$ und $p_u$ (schwach) voneinander erreichbar sind.
	Ansonsten nennen wir $p_v$ (schwach) ungültig.
\end{Def}

Für die Konstruktion von $s$ dürfen wir nur (schwach) gültige $\varepsilon$-Platzierungen der Knoten von $G_1$ betrachten, denn die
Wahl einer ungültigen Knoten-Platzierung schließt definitionsgemäß direkt aus, dass $s$ eine $\varepsilon$-Platzierung von $G_1$ sein kann.
Entsprechend löschen wir unter den in Schritt 1 ermittelten Knoten-Platzierungen alle diejenigen, die (schwach) ungültig sind.
\\
\\
Dabei ist zu beachten, dass nach dem Löschen einer (schwach) ungültigen $\varepsilon$-Platzierung von $v \in P(v)$
jede vor der Löschung noch (schwach) gültige $\varepsilon$-Platzierung eines Nachbarn von $v$ nun (schwach) ungültig geworden sein kann.
Unter Umständen war z.B. die Gültigkeit der Knoten-Platzierung eines Nachbarn von $v$ gerade durch die Erreichbarkeit zu der zuvor gelöschten
$\varepsilon$-Platzierung von $v$ bedingt.
In dem Sinne löschen wir rekursiv solange (schwach) ungültige $\varepsilon$-Platzierungen der Knoten in $G_1$, bis
keine (schwach) ungültigen Knoten-Platzierungen mehr existieren. Als Abbruchbedingung der Rekursion gilt daher, dass die Löschung der letzten bekannten
ungültigen Knoten-Platzierung keine weitere Löschung mehr impliziert.

\subsubsection{Schritt 3} \label{Schritt 3}
In diesem Schritt werden wie oben beschrieben alle Knoten-Platzierungen (rekursiv) bereinigt.
Um für eine Kante $\{u,v\} \in E_1$ zu entscheiden, welche Platzierungen der Knoten $u$ und $v$ voneinander (schwach) erreichbar sind, bedienen wir uns dafür der in
Schritt 2 berechneten Erreichbarkeiten. In Schritt 1 haben wir $O(n_1*m_2)$ Knoten Platzierungen ermittelt.

Für die schwache Erreichbarkeit haben wir in Schritt 2 für eine Kante $\{u,v\} \in E_1$ die zusammenhängende Komponente innerhalb von $T_{\varepsilon}(\{u,v\})$
und ihre enthaltenen Knoten-Platzierungen von $u$ und $v$ gespeichert.
\\
Ist nun eine Knoten-Platzierung $p_v \in P(v)$ ungültig, so muss $p_v$ aus allen entsprechenden Listen von Knoten-Platzierungen gelöscht werden, in
denen $p_v$ enthalten ist. Dies betrifft potentiell alle zu $v$ inzidenten Knoten, daher beträgt die Laufzeit zum Bereinigen von $p_v$ $O(deg(v))$.
Mit der Identität $\sum_{v \in V_1}(deg(v)) = 2m_1$ beträgt die Laufzeit zum Bereinigen aller ungültigen Knoten-Platzierungen $O(m_1*m_2)$.
\\
Für die nicht-schwache Erreichbarkeit haben wir für jede Knoten-Platzierung $p_v$ eine Liste mit erreichbaren Knoten-Platzierungen gespeichert.
Sollte $p_v$ ungültig sein, so müssen wir $p_v$ für jeden zu $v$ adjazenten Knoten aus den Listen der Knoten-Platzierungen entfernen, mit denen $p_v$ erreichbar ist.
Für jeden ajdazenten Knoten sind dies $O(m_2)$ Listen, daher beträgt die Laufzeit für die Löschung von $p_v$ $O(deg(v)*m_2)$.
Das Bereinigen aller Platzierungen beträgt entsprechend $O(m_1*m_2^2)$.
\\
\\
Nachdem Schritte 1-3 durchgeführt wurden, liefert uns ein Hilfssatz aus Akitaya et al. (siehe dazu Seite 13. Lemma 6) eine verbindliche Aussage über die Existenz
einer (schwachen) $\varepsilon$-Platzierung von $G_1$:

\begin{Lem} \label {Lemma 1}
	Sei $G_1$ ein Baum und für $v \in V_1$ sei $\tilde{P}(v)$ die Menge der (schwach) gültigen $\varepsilon$-Platzierungenvon $v$ nachdem
	alle (schwach) ungültigen ungültigen $\varepsilon$-Platzierungen der Knoten in $G_1$ rekursiv gelöscht wurden (analog wie in \ref{Schritt 3}).
	Enthält $\tilde{P}(v)$ für jedes $v \in V_1$ mindestens eine (schwach) gültige $\varepsilon$-Platzierung, so existiert
	eine schwache $\varepsilon$-Platzierung von $G_1$.
\end{Lem}

\begin{proof}
Für den Beweis konstruieren wir eine $\varepsilon$-Platzierung von $G_1$.
Wir wählen einen beliebigen Knoten $v_r \in V_1$ zur Wurzel und betrachten $G_1$ als gerichteten Baum ausgehend von $v_r$.
Wir ordnen $v_r$ einem beliebigen Punkt innerhalb einer seiner (schwachen) $\varepsilon$-Platzierung zu und bearbeiten anschließend iterativ alle
Knoten in $G_1$ ausgehend von der Wurzel.

Dabei wählen wir stets für einen Knoten $v \in V_1$, dessen Vorgänger bereits bereits zugewiesen wurde,
die $\varepsilon$-Platzierung $p_v \in P(v)$ von $v$ so, dass $p_v$
und die bereits ausgewählte (bzw. zugeordnete) $\varepsilon$-Platzierung $p_a$ des Vorgängers von $v$ voneinander (schwach) erreichbar sind.
Für die Kante zwischen $v$ und seinem Vorgänger können wir nun eine passende Kanten-Platzierungen wählen.
\\
Denn nach Vorraussetzung ist $p_a$ (schwach) gültig und somit muss ein $p_v$ mit der geforderten Erreichbarkeit zu $p_a$ existieren.
Nach Definition der (schwachen) Erreichbarkeit gilt, dass mindestens ein einfacher Weg in $G_2$ existiert, welcher $p_v$ und $p_a$ verbindet
und dessen (schwacher) Fréchet-Abstand mit der Kante zwischen $v$ und seinem Vorgänger nicht größer als $\varepsilon$ ist.
Einen solchen Weg wählen wir nun als $\varepsilon$-Platzierung für die Kante zwischen $v$ und seinem Vorgänger.
\\
Da wir $G_1$ als gerichteten Baum betrachten, sind nach endlich vielen Schritten ausgehend von der Wurzel ausgehend alle Knoten in $G_1$
entsprechend zugewiesen und ihre $\varepsilon$-Platzierungen
wurden mit den $\varepsilon$-Platzierungen ihrer Nachfahren durch einen einfachen Weg in $G_2$ verbunden.
Da $G_1$ als Baum insbesondere kreisfrei ist, konnte so jede Kante explizit in $G_1$ einer $\varepsilon$-Platzierung zugeordnet werden.
Die durch die Auswahl dieser $\varepsilon$-Platzierungen implizierte Graph-Zuordnung ist damit insgesamt eine $\varepsilon$-Platzierung von $G_1$.
\end{proof}

Über die Konstruktion aus dem Beweis von Lemma \ref{Lemma 1} erhalten wir einen ersten Ansatz zur Konstruktion einer $\varepsilon$-Platzierung gemäß der Einschränkungen und
des Optimalitätskriteriums.

\subsubsection{Optimale Kanten-Platzierungen}
Im Beweis von $\ref{Lemma 1}$ konnten wir zur Konstruktion einer $\varepsilon$-Platzierung von $G_1$ stets eine beliebige $\varepsilon$-Platzierung einer Kante wählen.
\\
\\
Diesen Ansatz werden wir erweitern, indem wir statt einer beliebigen jeweils nur eine lokal optimale $\varepsilon$-Platzierung einer Kante für die Graph-Zuordnung in Betracht ziehen.
Dabei minimiert eine lokal optimale Kanten-Platzierung $p_{\{u,v\}}$ den (schwachen) Fréchet-Abstand zu der Kante $\{u,v\}$.
Für ein paar Knoten-Platzierungen $p_u, p_v$ sei $$\Delta(p_u,p_v) = \min_{p_{{\{u,v}\}}} \delta_{(w)F}(\{u,v\},p_{\{u,v\}}),$$ wobei sich $p_{{\{u,v}\}}$ über alle
$\varepsilon$-Platzierungen von $\{u,v\}$ erstreckt. Die unter \ref{Zweite Einschränkung} geforderten Fixpunkte werden dafür vor der Berechnung von $\Delta$ gesetzt.

Wir erweitern Schritt 2 des Algorithmus um die Berechnung optimaler Kanten-Platzierungen und speichern für jede Kante $e=\{u,v\} \in G_1$ eine Liste $L_e$
mit Einträgen $(p_v, p_u, \Delta(p_v,p_v))$ für alle $p_v \in P(v)$, $p_u \in P(u)$ die (schwach) voneinander erreichbar sind.
\\
\\
TODO: Laufzeit und Speicher
\\
\\
Sofern $L_e$ für alle Knoten in $G_1$ berechnet ist und alle ungültigen Knoten-Platzierungen nach Ausführung von Schritt 3 (\ref{Schritt 3}) bereinigt sind,
reduziert sich die Konstruktion einer optimalen $\varepsilon$-Platzierung auf eine optimale Gesamt-Auswahl der jeweiligen Paare von Knoten-Platzierungen für jedes Paar adjazenter Knoten in $G_1$.
So eine Konstruktion ließe sich analog wie im Beweis zu Lemma $\ref{Lemma 1}$ realisieren und eine so ermittelte Graph-Zuordnung ist insbesondere auch eine $\varepsilon$-Platzierung von $G_1$.
Letztlich stellt dann die Frage, unter welcher der möglichen Auswahlen von Knoten-Platzierungen bei der Konstruktion von $s$ die Summe der Gewichte der durch $s$ implizierten Kanten-Platzierungen minimiert wird.

\subsubsection{Konstruktion einer optimalen $\varepsilon$-Platzierung von $G_1$}
Ein naiver Ansatz zur Berechnung von Min-Sum$_{(w)F}(G_1,G_2)$ wäre nun, alle möglichen Kombinationen der $\varepsilon$-Platzierungen der Knoten von $G_1$ über z.B. einen Backtracking-Algorithmus auszuschöpfen.
Dabei würden wir - beginnend bei dem ausgewiesenen Wurzelknoten $v_r$ - die Knoten und Kanten von $G_1$ wie in der Konstruktion der Graph-Zuordnung in $\ref{Lemma 1}$ zuordnen.
An jedem Knoten, wo es für die Auswahl einer Knoten-Platzierung mehr als eine Möglichkeit gibt, hätte der Backtracking-Algorithmus eine Abzweigung pro möglicher Auswahl.
Sobald wir erstmalig $G_1$ vollständig zugeordnet haben, speichern wir die Zuordnung $s$ sowie ihr bisheriges Gewicht $Sum_{(w)F}(s)$, welches sich als Summe der
paarweise gewählten Knoten-Platzierungen und ihren $\Delta$-Gewichten ergibt.
Für einen bereits zugeordneten Teilgraphen könnten wir sein Gewicht unter den bereits zugeordneten Kanten mitführen und backtracken, sobald dieses das bis zu diesem Iterationsschritt
minimalste Gewicht einer vollständigen Zuordnung von $G_1$ überschreitet. Nachdem der Algorithmus terminiert, hätten wir so Min-Sum$_{(w)F}(G_1,G_2)$ berechnet.
\\
\\
Allerdings ist trotz der Einschränkungen and die zu betrachteten Graph-Zuordnungen der Möglichkeitenraum im Allgemeinen zu groß
für einen solchen (brute-force) Ansatz.
Jeder Knoten in $G_1$ hat potentiell bis zu $m_2$ $\varepsilon$-Platzierungen und für
zwei benachbarte Knoten in $G_1$ gibt somit bis zu $m_2^2$ Möglichkeiten, die Knoten-Platzierungen zu kombinieren.
Insgesamt wächst die Anzahl der potentiellen Kombinationsmöglichkeiten exponentiell mit der Anzahl der Kanten bzw. der Anzahl der Knoten(**) von $G_1$.
(**) Da $G_1$ ein Baum ist, gilt $m_1 = n_1-1$.
\\
\\
Im letzten Schritt des Algorithmus konstruieren wir eine geeignete Suchstruktur für die Zuweisung und Gewichtung von Knoten-Platzierungen.
Anschließend werden wir eine $\varepsilon$-Platzierung $s$ konstruieren, die ebenfalls eine Min-Sum$_{(w)F}$ Zuordnung ist, also das Optimalitätskriterium erfüllt.
\\
\\
\subsubsection{Schritt 4}
Wir interpretieren $G_1$ nach wie vor (analog wie im Beweis zu Lemma \ref{Lemma 1}) als gerichteten Wurzelbaum (Out-Tree) mit beliebiger Wurzel $v_r$ und
konstruieren einen abstrakten Graphen $H = (V_H, E_H)$ als Suchstruktur für die Berechnung.
Jede (gültige) $\varepsilon$-Platzierung $p_v$ eines Knotens $v \in V_1$ wird durch einen entsprechenden Knoten $i_{p_v} \in V_H$ repräsentiert.
Für zwei Knoten-Platzierungen $p_v \in P(v)$ und $p_u \in P(u)$ gilt $(i_{p_u},i_{p_v}) \in E_H$ genau dann, wenn

\begin{enumerate}
	\item[(i)] $G_1$ die (gerichtete) Kante $(v,u)$ enthält und
	\item[(ii)] $p_v$ und $p_u$ (schwach) voneinander erreichbar sind.
\end{enumerate}

Insgesamt ist $H$ somit ein gerichteter, azyklischer Graph. Die Gerichtetheit folgt dabei direkt aus der Konstruktion der Kanten in $H$ und
ein Kreis in $H$ würde direkt der Vorraussetzung widersprechen, dass $G$ ein (gerichteter) Baum ist.
Da jeder Knoten in $G_1$ bis zu $m_2$ Knoten-Platzierungen hat, gilt $|V_H| \in O(n_1*m_2)$ und $|E_H| \in O(n_1*m_2^2)$.
\\
Wir induzieren durch $w_H: E_H \to \mathbb{R}$ mit $w_H(i_{p_v},i_{p_u}) = \Delta(p_v,p_v)$ eine Gewichtung der Kanten von $H$ und
initialisieren $w(p_v) = 0$ für alle Knoten-Platzierungen in $G_1$.
Wir werden nun die Knoten-Platzierungen iterativ zuweisen und eine optimale $\varepsilon$-Platzierung von $G_1$ berechnen.
Im Gegensatz zu der Konstruktion von Lemma \ref{Lemma 1} berechnen wir $s$ und die Gewichte der Knoten-Platzierungen \textit{bottom-up}.
Für einen Knoten $v \in V_1$, dessen Nachfahren ausschließlich Blätter in $G_1$ sind, setzen wir
\begin{equation}
	w(p_v) = \sum_{\text{$u:$ $u$ ist Nachfahre von $v$}} \min_{p_u \in P(u)} w(p_u) + w_H(p_v,p_u) \label{optimal placements}
\end{equation}
Dabei speichern wir die Zuordnung $s$ welche $w(p_v)$ realisiert für alle $p_v \in P(v)$ und löschen alle Nachfahren von $v$ aus $G_1$,
nachdem alle Knoten-Platzierungen von $v$ bearbeitet wurden.
Diese Bearbeitung eines Knotens in $G_1$ bezeichnen wir als einen Iterationsschritt \label{Iterationsschritt}

\begin{Lem} \label{Lemma 2}
	Schritt 4 berechnet in $O(n_1)$ Iterationsschritten \ref{Iterationsschritt} $\text{Min-Sum}_{(w)F}(G_1,G_2)$ und
	eine optimale $\varepsilon$-Platzierung von $G_1$.
\end{Lem}

\begin{proof}
Wir beweisen die Aussage über die Invariante, dass nach jedem Iterationsschritt \ref{Iterationsschritt} der Teilgraph (eingeschränkt auf
den zuletzt bearbeiteten Knoten) optimal zugeordnet ist.

Vor dem ersten Iterationsschritt ist das Gewicht aller Knoten-Platzierungen $0$.
Wir bezeichnen den aktualisierten Graphen $G_1$ nach dem $i$-ten Iterationsschritt mit $G_1^i$.
Für einen beliebigen Knoten $v \in V_1$, dessen Nachfahren Blätter in $G_1^0$ sind, wird das Gewicht aller Knoten-Platzierungen nun durch die Berechnung von (\ref{optimal placements})
für alle Nachfahren von $v$ minimiert. Insbesondere entspricht $w(v)$ gerade der Summe aller gewichteten Kanten-Platzierungen. Betrachten wir nun $s$ als die Abbildung, die $\min{w(p_v)}: p_v \in P(v)$ realisiert,
so ist $s$ offensichtlich eine Graph-Zuordnung, die Min-Sum$_{(w)F}(G_v, G_2)$ auf dem Teilgraphen $G_v$ - mit $v$ als Wurzel - einhält.
\\
Seien nun alle Teilgraphen in $G_1^i$ für ein beliebiges $i>1$ an allen bereits bearbeiteten Knoten optimal zugeordnet und sei $u \in V_1$ ein Knoten, dessen
Nachfahren Blätter in $G_1^i$ sind. Die Graph-Abbildung, die $\min{w(p_u)}: p_u \in P(u)$ realsiert, wählt unter Umständen nach der Berechnung von \ref{optimal placements}
für einen Nachfahren $\tilde{u}$ von $u$ eine andere Knoten-Platzierung als $\min{w(p_{\tilde{u}}}): p_{\tilde{u}} \in P(\tilde{u})$. Nach Vorraussetzung sind jedoch
wiederum alle (potentiellen) Nachfahren von $\tilde{u}$ für jede Knoten-Platzierung von $\tilde{u}$ optimal zugeordnet. Insgesamt ist damit die Graph-Abbildung, die $\min{w(p_u)}: p_u \in P(u)$ realisiert,
optimal in dem geforderten Sinne.
\\
\\
Da es zu Beginn weniger als $n_1$ Knoten mindestens einen Nachfahren haben und pro Iteration genau ein Knoten bearbeitet wird,
ended Schritt 4 nach $O(n_1)$ Iterationsschritten mit der Berechnung der Wurzel $v_r$ und es gilt nach obiger Argumentation:
\begin{equation}
	\min_{p_{v_r} \in P(v_r)}{w(p_{v_r})} = \text{Min-Sum}_{(w)F}(G_1,G_2) \label {last one}
\end{equation}
Die Gleichung (\ref{last one}) realisierende Graph-Abbildung ist (nach \ref{Lemma 1}) eine $\varepsilon$-Platzierung von $G_1$.
\\
\end{proof}

Insgesamt setzt sich der Algorithmus also aus den folgenden Einzelschritten zusammen:
\begin{enumerate}
	\item[1)] Schritt 1: Berechnung der $\varepsilon$-Platzierungen der Knoten von $G_1$
	\item[2)] Schritt 2: Berechnung der (schwachen) Erreichbarkeiten und optimaler Kanten-Platzierungen
	\item[3)] Schritt 3: Löschung aller ungültigen $\varepsilon$-Platzierungen der Knoten von $G_1$
	\item[4)] Schritt 4: Konstruktion der Suchstruktur $H$ und iterative Berechnung von Min-Sum$_{(w)F}(G_1, G_2)$ und einer optimalen $\varepsilon$-Platzierung von $G_1$.
\end{enumerate}

\begin{Satz}
	Sei $G_1$ ein Baum und sei $\varepsilon \geq \vec{\delta}_{(w)F}(G_1,G_2)$.
	So lässt sich unter Einhaltung der Einschränkung \ref{Zweite Einschränkung} eine $\varepsilon$-Platzierung $s$ von $G_1$
	mit einer Laufzeitkomplexität von $O(n_1*m_2^3)$ und einer Speicherkomplexität von $O(n_1*m_2^2)$ berechnen, so dass für jede
	andere $\varepsilon$-Platzierung $\tilde{s}$ von $G_1$ gilt:
	$$\sum_{e \in E_1}\delta{(w)F}(e, s(e)) \leq \sum_{e \in E_1}\delta{(w)F}(e, \tilde{s}(e)).$$
\end{Satz}

\begin{proof}
Die Korrektheit des Algorithmus folgt aus Lemma \ref{Lemma 2}.
\\
TODO: Zeitkomplexität und Speicherkomplexität zur Berechnung von $H$ begründen.
\\
\\
Zur Berechnung von Gleichung (1) betrachten für eine feste Knoten-Platzierung $p_v \in P(v)$ den zur Lösung der Gleichung relevanten Teilgraph von $H$,
bestehend aus den Knoten-Platzierungen von $v$ sowie deren Nachfahren. Dieser Teilgraph weist somit für jede fixierte Knoten-Platzierung eine Komplexität von $O(m_2^2)$ auf.
Sofern $v$ nicht die Wurzel ist, gibt es $deg(v)-1$ Nachfahren von $v$. Ferner gilt $|P(v)| \in O(m_2)$. Damit beträgt die Zeitkomplexität für Gleichung (1) für alle
Knoten-Platzierungen von $v$ insgesamt
\begin{equation}
	O(deg(v)*m_2^3).
\end{equation}
Mit (2) und der Identität
\begin{equation}
	\sum_{v \in V_1} deg(v) = 2*m_1 = 2(n-1)
\end{equation}
ergibt sich die schließlich die Laufzeitkomplexität von $O(n_1*m_2^3).$
\end{proof}

\subsection{Ein Beispiel}
Anhand eines kleinen Beispiels wollen wir den eben beschriebenen Algorithmus nun demonstrieren.
TODO: Skizze und Beispielrechnung ergänzen

\section{Komplexität}

\subsubsection{NP-Schwerheit von Min-Sum-Graph-Abstand$_{(w)F}$}

Abschließend wollen wir zeigen, dass die Berechnung des Min-Sum-Graph-Abstands$_{(w)F}$ ohne Bedingungen an die Graphen $G_1$ und $G_2$ im Allgemeinen
NP-schwer ist. Ein für die Konstruktion des Beweises ähnliches Setting finden wir in [2] (Seite), wo die NP-Schwerheit des Graph-Abstands
über eine Reduktion von \textit{Binary Constraint Satifaction Problem (CSP)} gezeigt wird.
In unserem Beweis der NP-Schwerheit für den Min-Sum-Graph-Abstand orientieren wir uns im Wesentlichen an dieser Konstruktion.

\begin{Def}
	Binary Constraint Satisfaction Problem
	Ein \textit{Binary Constraint Satisfaction Problem} beschreibt folgendes Entscheidungsproblem:
	\\
	Gegeben eine Instanz $\langle X,D,C \rangle$ bestehend aus
	$$ \text{einer Menge von \textit{Variablen }}X = \{x_1, x_2, ..., x_n\},$$
	$$ \text{einer Menge von \textit{Domänen }}D = \{D_1, D_2, ..., D_n\} $$
	$$ \text{und einer Menge von \textit{Bedingungen }}C = \{C_1, C_2, ..., C_k\}. $$
	Für jede Variable $ x_i \in X$ beschreibt die Domäne $ D_i \in D$ die Menge ihrer möglichen Wertzuweisungen.
	Eine Bedingung $C_{i,j} \in C$ spezifiert für je zwei unterschiedliche Variablen $x_i, x_j \in X$ eine Relation $R_{C_{i,j}}$ $\subseteq D_v \times D_w$.
	Wir nennen ein Wertepaar $(d_i, d_j) \in D_i \times D_j$ für eine vorhandene Bedingung $C_{i,j}$ an die Variablen $x_i,x_j$ \textit{zulässig}, wenn $(d_i,d_j) \in R_{C_{i,j}}$,
	ansonsten \textit{verletzt} das Wertepaar $(d_i, d_j)$ die Bedingung $C_{i,j}$ und wir nennen $(d_i,d_j)$ \textit{unzulässig}.
	\\
	Die Fragestellung ist nun, ob alle Variablen einem Wert aus ihrer Domäne zugewiesen werden können, so dass alle mit Bedingungen versehenden Wertepaare zulässig sind.
	In diesem Falle nennen wir $\langle X,D,C \rangle$ \textit{lösbar}.
	\\
	\\
	TODO: Referenz, dass CSP NP-schwer ist
\end{Def}

\begin{Satz} \label{Satz NP-Schwerheit}
	Theorem: Seien $G_1$ und $G_2$ geometrische Graphen und sei $\varepsilon \geq 0$.
	Das Entscheidungsproblem $$ \textit{Min-Sum}_{(w)F}(G_1, G_2) \leq  \varepsilon $$ ist NP-schwer.
\end{Satz}

Sei $\langle X,D,C \rangle$ ein beliebiges Binary Constraint Satisfaction Problem.
\\
\\
Wir repräsentieren jede Variable $x_i \in X$ durch einen Knoten $v_i \in V_1$ in $G_1$ und für jede Bedingung $C_{i,j}$ an die Variablen $x_i, x_j$
hat $G_1$ die Kante $\{v_i, v_j\}$. Wir setzen $\varepsilon = |E_1|$.
\\
Wir betten $G_1$ so in die euklidische Ebene ein, dass sich für je zwei Knoten $v_i,v_j$ ihre $\varepsilon$-Bälle nicht berühren und
sich der $\varepsilon$-Schlauch einer Kante $e \in E_1$ genau dann mit dem $\varepsilon$-Ball eines Knotens $v \in V_1$ überlappt, wenn $e$ und $v$ inzident sind.
\\
\\
Eine solche Einbettung für $G_1$ lässt sich z.B. realisieren, indem wir die Knoten in $G_1$ (gleichmäßig) auf einem Kreis mit entsprechend großem Radius verteilen.
\\
Jeder Wert $d_{i,a} \in D_i$ wird durch einen Knoten $u_{i,a}$ in $G_2$ repräsentiert und wir betten $_{i,a}$ beliebig innerhalb des 1-Balles $B_1(v_i)$ von $v_i$ ein.
Für jedes Wertepaar $d_{i,a} \in D_i, d_{j,b} \in D_j$ enthält $G_2$ genau dann die Kante $\{u_{i,a},u_{j,b}\}$, wenn die Wertekombination $(d_{i,a},d_{j,b})$
zulässig ist.
\\
Alle einzubettenen Kanten von $G_1$ und $G_2$ ergeben sich implizit (Geradenstücke) zwischen den entsprechenden Knoten-Einbettungen.
Insgesamt behaupten wir, dass sich die oben beschriebene Einbettung von $G_1$ und $G_2$ in Polynomialzeit realisieren lässt.
\\
\\
TODO: Figure XX zeigt die Konstruktion anhand eines kleinen Beispiels
\\
\\
Wir wollen nun zeigen, dass
$$ \min_{s: G_1 \to G_2} \sum_{e \in E_1} \delta_{(w)F}(e, s(e)) \leq \varepsilon \iff \langle X,D,C \rangle \text{ ist lösbar}$$
"$\Leftarrow$":
\\
Sei $\langle X,D,C \rangle$ lösbar.
\\
Dann existiert eine Wertezuweisung $(\tilde{d_1},\tilde{d_2},...,\tilde{d_n}) \in {D_1 \times D_2 \times ... \times D_n},$ welche keine der Bedingungen verletzt.
\\
\\
Wir definieren eine Abbildung $\tilde{s}:G_1 \to G_2$ mit $\tilde{s}(v_i) = u_{\tilde{d_i}}$.
Nach Konstruktion von $G_2$ existiert für jedes $\tilde{d_i}$ ein entsprechendes $u_{\tilde{d_i}} \in G_2$.
\\
Ferner existiert für eine beliebige Kante $\{v_i, v_j\} \in E_1$ die Kante $\{u_{\tilde{d_i}}, u_{\tilde{d_j}}\} \in E_2$ und diese ist
und da das mit $\{u_{\tilde{d_i}}, u_{\tilde{d_j}}\}$ assoziierte Wertepaar $(\tilde{d_i},\tilde{d_j})$ per Vorraussetzung zulässig ist,
liegt $\{u_{\tilde{d_i}}, u_{\tilde{d_j}}\}$ innerhalb von $T_1(\{v_i, v_j\}$ und die Randpunkte liegen respektive innerhalb von $B_1(v_i)$ und $B_1(v_j)$.
\\
\\
Wir erweitern $\tilde{s}$ insofern, dass $\{v_i, v_j\}$ durch $s$ so auf $\{u_{\tilde{d_i}}, u_{\tilde{d_j}}\}$ abgebildet wird,
dass $\delta_{(w)F}(\{v_i, v_j\}, s(\{v_i, v_j\}) \leq 1$. Bilden wir jede Kante von $G_1$ auf diese Weise auf $G_2$ ab, so ist $\tilde{s}$ eine Graph-Zuordnung
und $\delta_{(w)F}(e, \tilde{s}) \leq 1$ für jedes $e \in E_1$.
\\
\\
Damit ist
\begin{equation} \label{beweis_1}
	\sum_{e \in E_1} \delta_{(w)F}(e, \tilde{s}(e)) \leq \varepsilon
\end{equation}
\\
Über die Identität $$\min_{s: G_1 \to G_2} \sum_{e \in E_1} \delta_{(w)F}(e, s(e)) \leq \sum_{e \in E_1} \delta_{(w)F}(e,\tilde{s}(e)) $$
und (\ref{beweis_1}) erhalten wir
$$\min_{s: G_1 \to G_2} \sum_{e \in E_1} \delta_{(w)F}(e, s(e)) \leq \varepsilon .$$
\\
\\
"$\Rightarrow$":
\\
Sei $$\min_{s: G_1 \to G_2} \sum_{e \in E_1} \delta_{(w)F}(e, s(e)) \leq {\varepsilon}.$$
\\
\\
So ist $s(e)$ für alle $e \in E_1$ eine (schwache) $\varepsilon$-Platzierung von $e$,
da ansonsten $\delta_{(w)F}(\tilde{e}, s(\tilde{e})) > \varepsilon$ für ein $\tilde{e} \in E_1$ und damit insbesondere $\sum_{{e}\in E_1} \delta_{(w)F}(e, s(e)) > \varepsilon$.
(*)
\\
\\
Zusätzlich wollen wir argumentieren, dass $s(e)$ für alle $e \in E_1$ eine (schwache) 1-Platzierung von $e$ ist.

Wir haben bereits argumentiert, dass jedes Bild einer Kante von $G_1$ unter $s$ eine $\varepsilon$-Platzierung sein muss.
Damit liegen die Randpunkte von $s(e)$ insbesondere innerhalb der $\varepsilon$-Platzierungen der zu $e$ inzidenten Knoten.
Wenn $s(e)$ eine $\varepsilon$-Platzierung ist von $e$, so muss $s(e)$ insbesondere auch eine 1-Platzierung von $e$ sein.
\\
Dies ergibt sich aus der Vorraussetzung, dass $s$ eine Min-Sum$_{(w)F}$ Zuordnung ist und dass aufgrund der Konstruktion
von $G_1$ und $G_2$ jede $\varepsilon$-Platzierung von $e$ sich grundsätzlich auch als 1-Platzierung von $e$ realisieren lässt.
\\
Denn die Randpunkte von $s(e)$ lassen sich innerhalb der 1-Bälle versetzten und da alle Kanten von $G_2$ innerhalb von $T_{\varepsilon}(e)$
per Konstruktion auch innerhalb von $T_1(e)$ verlaufen, existiert in $G_2$ eine 1-Platzierung von $e$.
\\
\\
Damit ist für eine Kante $\{v_i, v_j\} \in E_1$ ihr Bild $s(\{v_i, v_j\})$ stets eine 1-Platzierung von $\{v_i, v_j\}$. (**)
\\
\\
Im Falle des Fréchet-Abstands gilt damit, dass wir durch eine $\text{Min-Sum}_F$ Zuordnung $s: G_1 \to G_2$ das Bild $s(\{v_i, v_j\})$ einer Kante
eindeutig mit einer Kante $\{u_{i,a}, u_{j,b}\} \in E_2$ identifizieren können. Gemeint ist damit genau die Kante, welche
die entsprechenden $1$-Platzierungen der Knoten $v_i$ und $v_j$ verbindet und in $T_1(\{v_i, v_j\})$ liegt. Die Eindeutigkeit dieser Kante folgt direkt aus der
Konstruktion von $G_2$.
\\
Durch (**) ist gewährleistet, dass für die Kante $\{u_{i,a}, u_{j,b}\} \in E_2$, ihren assoziierten Wertezuweisungen $(d_{i,a}, d_{j,b}) \in D_i \times D_j$
und die Bedingung $C_{i,j} \in C$ an die Variablen $x_i, x_j$ gilt:
$$(d_{i,a},d_{j,b}) \in R_{C_{i,j}}$$
Damit ist im Falle des Fréchet-Abstands $\langle X,D,C \rangle$ erfüllbar.
\\
\\
Für den schwachen Fréchet-Abstand gilt das Argument, dass wir das Bild einer Kante in $E_1$ unter $s$ eindeutig mit einer Kante in $E_2$ identifizieren können, allgemein nicht.

Dies liegt daran, dass grundsätzlich jedes beliebige Knotenpaar $u_{i,a}, u_{i,b} \in V_2$ mit $u_{i,a} \in B_1(v_i)$, $u_{i,b} \in B_1(v_j)$ eine Kante in $G_2$ haben kann.
\\
So existieren Wege in $G_2$ bestehendend aus mindestens 3 Kanten innerhalb von $T_1(\{v_i, v_j\}$, deren Startpunkt in $B_1(v_i)$ und deren Endpunkt in $B_1(v_j)$ liegt.
Ein solcher Weg $W$ ist dabei möglicherweise - da er vollständig innerhalb von $T_1(\{v_i, v_j\}$ liegt - eine schwache 1-Platzierung der Kante $\{v_i, v_j\}$, also
$$ \delta_{wF}(\{v_i, v_j\}, W) \leq 1.$$
\\
\\
TODO: Skizze
\\
\\
Um dies zu umgehen, fügen wir mittig auf jeder Kante $\{v_i, v_j\} \in E_1$ einen zusätzlichen Knoten $v_{ij}$ in $G_1$ ein,
so dass $B_1(v_{ij}) \cap B_1(v_i) = B_1(v_{ij}) \cap B_1(v_j) = \emptyset$.
\\
\\
Hinweis: Hierfür können wir initial auch $\varepsilon = \max \{m_1, 4\}$ fordern.
\\
\\
Die Kante $\{v_i, v_j\}$ zerfällt dabei in die zwei Kanten $\{v_i, v_{ij}\}$, $\{v_{ij},v_j\}$ und
jede 1-Platzierung von $\{v_i, v_j\}$ zerfällt dabei zwei 1-Platzierungen der Kanten $\{v_i, v_{ij}\}$ und $\{v_{ij}, v_j$\}.
\\
\\
TODO: Skizze
\\
\\
TODO: Ergänze Erklärung, warum das Problem jetzt gelöst ist.
\\
\\
Wir bezeichnen mit $\tilde{G_1}=(\tilde{V_1}, \tilde{E_1})$ den Graphen, den wir durch die oben beschriebene Transformation erhalten.
\\
Gilt nun
$$ \min_{s: \tilde{G_1} \to G_2} \sum_{e \in E_1} \delta_{wF}(e, s(e)) \leq 2m_1, $$
so erhalten wir für jede Kante $\{v_i, v_j\} \in E_1$ und ihre Zerlegung $\{v_i, v_{ij}\},\{v_{ij}, v_j\} \in \tilde{E_1}$
über $s(\{v_i, v_{ij}\},\{v_{ij}, v_j\})$ die eindeutige, assoziierte Kante $\{u_{i,a}, u_{i,b}\} \in E_2$.
Die durch $\{u_{i,a}, u_{j,b}\} \in E_2$ repräsentierte Wertezuweisung $(d_{i,a}, d_{j,b})$ verletzt dabei nicht die Bedingung an die
durch $v_i$ und $v_j$ repräsentierten Variablen $x_i, x_j$ und ist damit gültig.
\\
\\
Damit ist $\langle X,D,C \rangle$ lösbar. \qed
\\
\\
\section{Ausblick}
In dieser Arbeit haben wir uns, motiviert durch das Ziel optimale Zuordnungen auf geometrischen Graphen zu untersuchen, mit dem
Min-Sum-Graph-Abstand$_{(w)F}$ beschäftigt. Dabei haben wir die Frage der NP-Schwerheit des Min-Sum-Graph-Abstands$_{(w)F}$ für allgemeine
Graphen geklärt und - falls $G_1$ ein Baum ist und wir die Menge der Graph-Zuordnungen (wie in \ref{Einschränkungen} beschrieben) einschränken -
einen Polynomialzeit-Algorithmus zur Berechnung von Min-Sum-Graph-Abstand$_{(w)F}(G_1, G_2)$ beschrieben.
\\
Dabei verbleiben noch einige offene Fragen bezüglich der Komplexität.
Buchin et al. gehen des Weiteren davon aus, dass sich der Min-Sum-Graph-Abstand$_{(w)F}$ auch auf planaren Graphen und
auf Bäumen ohne die notwendige Einschränkung (aus \ref{Zweite Einschränkung}) ebenfalls NP-schwer ist.
Formale Beweise dieser Annahmen stehen dabei noch aus.
\\
\\
Allgemein beschreibt der Min-Sum-Graph-Abstand$_{dist}$ eine ganze Klasse von Abstandsmaßen auf Graphen, deren Mitglieder sich durch die Wahl
eines geeigneten Abstandsmaßes für die Gewichtung der Kanten-Zuordnungen unterscheiden.
Grundsätzlich sind die Eigenschaften des Min-Sum-Graph-Abstands unter anderen Abstandsmaßen zu betrachten. Hier bietet sich z.B. der
diskrete Fréchet-Abstand als geeigneter Kandidat an. Wir behaupten, dass wir aufgrund seiner inherenten Eigenschaft die in $\ref{Zweite Einschränkung}$
geforderten Fixpunkte zur Einhaltung der polynomiellen Laufzeit nicht benötigen.
\\
Wir haben bei unserer Betrachtung des Min-Sum${(w)f}$ Abstands bisher nur ein Mitglied dieser oben beschriebenen Klasse kennengelernt und
damit einen kleinen Einblick in den Raum der offenen Möglichkeiten gewagt.
\newpage\null\thispagestyle{empty}\newpage
%   Eventuell eine Leerseite vor der Literaturangabe, falls diese sonst auf einer Rückseite angegeben würde. (Seitennummer muss ungerade sein!)

\begin{thebibliography}{3}
	\bibitem{Buchin}
		Maike Buchin, Bernhard Kilgus. Distance Measures for Embedded Graphs - Optimal Graph Mappings.
		\textit{European Workshop on Computational Gemoetry,} 2020.

	\bibitem{Akitaya}
		Hugo Akitaya, Maike Buchin, Bernhard Kilgus, Stef Sijben, Carola Wenk. Distance measures for embedded graphs
		\textit{Computational Geometry,} Volume 95, 2021.

	\bibitem{Alt}
		Hemlut Alt, Michael Godau. Computing the Fréchet distance between two polygonal curves.
		\textit{Int. Journal of Computational Geometry and Applications,} 5:75-91, 1995.
\end{thebibliography}

% Symbolverzeichnis definieren
%\nomenclature{$c$}{Speed of light in a vacuum inertial frame}
%\nomenclature{$h$}{Planck constant}

%\printnomenclature
\end{document}
